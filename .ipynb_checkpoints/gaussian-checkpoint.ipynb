{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fb910e",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44ab228",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_reduced.csv')\n",
    "# data = pd.read_csv('data/data_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d605ff5d",
   "metadata": {
    "pycharm": {
     "name": "#%% SPLIT ON THE FEATURES\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_columns_elasticity(data):\n",
    "    xE = data.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact', 'impurityImpact', 'impuritySTRENGTH', 'impurityStrainbreak', 'matrixImpact', 'matrixSTRENGTH', 'matrixStrainbreak'], axis=1)\n",
    "    yE = data[['blendE']]\n",
    "    return xE, yE\n",
    "#     xE = data.drop(['blendSTRENGTH','blendStrainbreak', 'blendImpact', 'impurityImpact', 'impuritySTRENGTH', 'impurityStrainbreak', 'matrixImpact', 'matrixSTRENGTH', 'matrixStrainbreak'], axis=1)\n",
    "#     return xE\n",
    "\n",
    "class PreprocessTypePlastic:\n",
    "    def transform(self, X):\n",
    "        encoded = pd.get_dummies(X, columns=['MinorityPolymer'])\n",
    "        encoded = encoded.drop('MajorityPolymer', axis=1)\n",
    "        return encoded\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "# def preprocess_type_plastic(data):\n",
    "#     encoded = pd.get_dummies(data, columns = ['MinorityPolymer'])\n",
    "#     encoded = encoded.drop('MajorityPolymer', axis =1)\n",
    "#     return data\n",
    "    \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xE, yE, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40913b9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(rf.feature_importances_)\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf, X_test, y_test, n_repeats=10, random_state=0, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=xE.columns[sorted_importances_idx],\n",
    ")\n",
    "print(importances)\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()\n",
    "ax.figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228d806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importances_idx.size\n",
    "# xE.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9704742",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= sorted_importances_idx.size\n",
    "fsRFPermutation = xE.columns[sorted_importances_idx[n-10:n]]\n",
    "# reversing order \n",
    "fsRFPermutation = fsRFPermutation[n:None:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819e3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsRFPermutation[n:None:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17f33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sorted in ascending odere!!\n",
    "def fs_permutation_importance(x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xE, yE, test_size = 0.1, random_state = 0)  \n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # y_train = y_train.values.flatten()\n",
    "    # Fit the model on the training data\n",
    "    rf.fit(X_train, y_train.values.flatten())\n",
    "\n",
    "    result = permutation_importance(\n",
    "        rf, X_test, y_test, n_repeats=10, random_state=0, n_jobs=2\n",
    "    )\n",
    "\n",
    "    sorted_importances_idx = result.importances_mean.argsort()\n",
    "    return sorted_importances_idx, result\n",
    "\n",
    "\n",
    "def get_best_t(x, sorted_idx, t):\n",
    "    n= sorted_idx.size\n",
    "#     print(n)\n",
    "    fsRFPermutation_names = x.columns.values[sorted_idx[n-t:n]]\n",
    "    # reversing order \n",
    "#     fsRFPermutation_names = fsRFPermutation[n:None:-1]\n",
    "    \n",
    "    fsRFPermutation_idx = sorted_idx[n-t:n]\n",
    "#     print(fsRFPermutation_idx)\n",
    "#     fsRFPermutation_idx = fsRFPermutation_idx[n:None:-1]\n",
    "#     print(fsRFPermutation_idx)\n",
    "    return fsRFPermutation_names, fsRFPermutation_idx\n",
    "\n",
    "    \n",
    "# assuming in order already and only best t     \n",
    "def get_plot(result, xE, sorted_idx, title):\n",
    "    importances = pd.DataFrame(\n",
    "        result.importances[sorted_idx].T,\n",
    "        columns=xE.columns.values[sorted_idx],\n",
    "    )\n",
    "#     print(importances)\n",
    "    ax = importances.plot.box(vert=False, whis=10)\n",
    "    ax.set_title(title)\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()\n",
    "    ax.figure.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfeded",
   "metadata": {},
   "source": [
    "# comparing partitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff68d7",
   "metadata": {},
   "source": [
    "#### P vs NP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f2a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = pd.read_csv('data/data_reduced_p.csv')\n",
    "NP = pd.read_csv('data/data_reduced_np.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485ef214",
   "metadata": {},
   "outputs": [],
   "source": [
    "xPE = P.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact', 'impurityImpact', 'impuritySTRENGTH', 'impurityStrainbreak', 'matrixImpact', 'matrixSTRENGTH', 'matrixStrainbreak'], axis=1)\n",
    "yPE = P[['blendE']]\n",
    "xNPE = P.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact', 'impurityImpact', 'impuritySTRENGTH', 'impurityStrainbreak', 'matrixImpact', 'matrixSTRENGTH', 'matrixStrainbreak'], axis=1)\n",
    "yNPE = P[['blendE']]\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(xPE, yPE, test_size = 0.1, random_state = 0)\n",
    "X_trainNP, X_testNP, y_trainNP, y_testNP = train_test_split(xNPE, yNPE, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d10978",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfP = RandomForestRegressor()\n",
    "\n",
    "# y_train = y_train.values.flatten()\n",
    "# Fit the model on the training data\n",
    "rfP.fit(X_trainP, y_trainP)\n",
    "# print(rfP.feature_importances_)\n",
    "\n",
    "resultP = permutation_importance(\n",
    "    rfP, X_testP, y_testP, n_repeats=10, random_state=0, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idxP = resultP.importances_mean.argsort()\n",
    "importancesP = pd.DataFrame(\n",
    "    resultP.importances[sorted_importances_idxP].T,\n",
    "    columns=xPE.columns[sorted_importances_idxP],\n",
    ")\n",
    "# print(importancesP)\n",
    "ax = importancesP.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set) from Polyfine family\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()\n",
    "ax.figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c0ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking best 10 features \n",
    "nP= sorted_importances_idxP.size\n",
    "fsRFPermutationP = xPE.columns[sorted_importances_idxP[nP-10:nP]]\n",
    "# reversing order \n",
    "fsRFPermutationP = fsRFPermutationP[nP:None:-1]\n",
    "fsRFPermutationP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c4c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfNP = RandomForestRegressor()\n",
    "\n",
    "# y_train = y_train.values.flatten()\n",
    "# Fit the model on the training data\n",
    "rfNP.fit(X_trainNP, y_trainNP)\n",
    "# print(rfNP.feature_importances_)\n",
    "\n",
    "resultNP = permutation_importance(\n",
    "    rfNP, X_testNP, y_testNP, n_repeats=10, random_state=0, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idxNP = resultNP.importances_mean.argsort()\n",
    "importancesNP = pd.DataFrame(\n",
    "    resultNP.importances[sorted_importances_idxNP].T,\n",
    "    columns=xNPE.columns[sorted_importances_idxNP],\n",
    ")\n",
    "# print(importancesNP)\n",
    "ax = importancesNP.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances on NONPoly family\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()\n",
    "ax.figure.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75aafecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nNP= sorted_importances_idxNP.size\n",
    "fsRFPermutationNP = xNPE.columns[sorted_importances_idxNP[nNP-10:nNP]]\n",
    "# reversing order \n",
    "fsRFPermutationNP = fsRFPermutationNP[nNP:None:-1]\n",
    "fsRFPermutationNP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87df16",
   "metadata": {},
   "source": [
    "### Matrix Topology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401ad8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "branched = pd.read_csv('data/data_reduced_branched_topo.csv')\n",
    "linear = pd.read_csv('data/data_reduced_linear_topo.csv')\n",
    "branched.drop('Matrix_topology', axis=1)\n",
    "linear.drop('Matrix_topology', axis=1)\n",
    "xBTE, yBTE = select_columns_elasticity(branched)\n",
    "xLTE, yLTE = select_columns_elasticity(linear)\n",
    "# tehy have polymers already 1hot enconded\n",
    "\n",
    "fsRFPermutationBT, resultB= fs_permutation_importance(xBTE, yBTE)\n",
    "fsRFPermutationLT, resultL = fs_permutation_importance(xLTE, yLTE)\n",
    "\n",
    "# getting 10 best features \n",
    "fsRFPermutationBT_names, fsRFPermutationBT_idx = get_best_t(x= xBTE, sorted_idx= fsRFPermutationBT, t= 10 )\n",
    "fsRFPermutationLT_names, fsRFPermutationLT_idx = get_best_t(x= xLTE, sorted_idx= fsRFPermutationLT, t= 10 )\n",
    "# print(fsRFPermutationBT_idx)\n",
    "\n",
    "get_plot(result=resultB, xE=xBTE, sorted_idx= fsRFPermutationBT_idx, title= \"Permutation Importances Branched Topology\")\n",
    "get_plot(result= resultL, xE=xLTE, sorted_idx= fsRFPermutationLT_idx, title= \"Permutation Importances Linear Topology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e7e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLTE.columns.values[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed613e3",
   "metadata": {},
   "source": [
    "### Matrix Crystalinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high = pd.read_csv('data/data_reduced_high_crys.csv')\n",
    "low = pd.read_csv('data/data_reduced_low_crys.csv')\n",
    "amorp=  pd.read_csv('data/data_reduced_amorp_crys.csv')\n",
    "high.drop('Matrix_crystallinity', axis=1)\n",
    "low.drop('Matrix_crystallinity', axis=1)\n",
    "amorp.drop('Matrix_crystallinity', axis=1)\n",
    "\n",
    "xHCE, yHCE = select_columns_elasticity(high)\n",
    "xLCE, yLCE = select_columns_elasticity(low)\n",
    "xACE, yACE = select_columns_elasticity(amorp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsRFPermutationHC, resultHC= fs_permutation_importance(xHCE, yHCE)\n",
    "fsRFPermutationLC, resultLC = fs_permutation_importance(xLCE, yLCE)\n",
    "fsRFPermutationAC, resultAC = fs_permutation_importance(xACE, yACE)\n",
    "# getting 10 best features \n",
    "fsRFPermutationHC_names, fsRFPermutationHC_idx = get_best_t(x= xHCE, sorted_idx= fsRFPermutationHC, t= 10 )\n",
    "fsRFPermutationLC_names, fsRFPermutationLC_idx = get_best_t(x= xLCE, sorted_idx= fsRFPermutationLC, t= 10 )\n",
    "fsRFPermutationAC_names, fsRFPermutationAC_idx = get_best_t(x= xACE, sorted_idx= fsRFPermutationAC, t= 10 )\n",
    "\n",
    "get_plot(result=resultHC, xE=xHCE, sorted_idx= fsRFPermutationHC_idx, title= \"Permutation Importances High Crystalinity\")\n",
    "get_plot(result= resultLC, xE=xLCE, sorted_idx= fsRFPermutationLC_idx, title= \"Permutation Importances Low Crystalinity\")\n",
    "get_plot(result=resultAC, xE=xACE, sorted_idx= fsRFPermutationAC_idx, title= \"Permutation Importances amorphous Crystalinity\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa223c",
   "metadata": {},
   "source": [
    "### Polymer Matrix type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HDPE = pd.read_csv('data/datadata_reduced_hdpe.csv')\n",
    "LDPE = pd.read_csv('data/datadata_reduced_ldpe.csv')\n",
    "LLDPE = pd.read_csv('data/datadata_reduced_lldpe.csv')\n",
    "PET = pd.read_csv('data/datadata_reduced_pet.csv')\n",
    "PS1 = pd.read_csv('data/datadata_reduced_ps1.csv')\n",
    "PS2 = pd.read_csv('data/datadata_reduced_ps2.csv')\n",
    "PP1 = pd.read_csv('data/datadata_reduced_pp1.csv')\n",
    "PP2 = pd.read_csv('data/datadata_reduced_pp2.csv')\n",
    "PP3 = pd.read_csv('data/datadata_reduced_pp3.csv')\n",
    "PA = pd.read_csv('data/datadata_reduced_pa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09036e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329cdf3",
   "metadata": {},
   "source": [
    "### trying to automate with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e88bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def permutation_feature_plastic(data):\n",
    "#     data=(\n",
    "#         data\n",
    "#         .pipe(preprocess_type_plastic)\n",
    "#         .pipe(select_columns_elasticity)\n",
    "#     )\n",
    "    \n",
    "pipeline1 = Pipeline([\n",
    "    ('plastics',preprocess_type_plastic),\n",
    "    ('elasticity',select_columns_elasticity)\n",
    "    \n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "#     split data here and feed to RF\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('permutation',fs_permutation_importance ),\n",
    "    ('ten best', get_best_t)\n",
    "    \n",
    "])\n",
    "\n",
    "X = pipeline1.fit_transform(data)\n",
    "y = data['blendE']\n",
    "best_features = pipeline2.fit_transform(X, y, permutation__t=10)\n",
    "\n",
    "print(\"Best Features:\")\n",
    "print(best_features)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966940ce",
   "metadata": {},
   "source": [
    "# gaussian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the toy data.\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Perform interpolation prediction.\n",
    "y_pred_train = gpr.predict(X_train)\n",
    "\n",
    "\n",
    "# Perform extrapolation prediction. The model should\n",
    "# not perform very well here.\n",
    "y_pred = gpr.predict(X_test)\n",
    "\n",
    "\n",
    "plt.plot(xE['matrixE'], yE, \"k\", linewidth = 6)\n",
    "plt.plot(X_train, y_pred_train, \"r\")\n",
    "plt.plot(X_test, y_pred, \"b\")\n",
    "plt.legend([\"Training data\", \"Interpolation\", \"Extrapolation\"])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3eadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
