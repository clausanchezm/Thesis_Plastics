{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca79881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/thesis_plastics'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccb917e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd() + '/data/data_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcdd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matrix_family</th>\n",
       "      <th>Matrix_crystallinity</th>\n",
       "      <th>Matrix_topology</th>\n",
       "      <th>Matrix_SCB</th>\n",
       "      <th>Matrix_LCB</th>\n",
       "      <th>Matrix_viscosity</th>\n",
       "      <th>Contaminant_family</th>\n",
       "      <th>Contaminant_crystallinity</th>\n",
       "      <th>Contaminant_topology</th>\n",
       "      <th>Contaminant_SCB</th>\n",
       "      <th>...</th>\n",
       "      <th>MinorityPolymer_HDPE1</th>\n",
       "      <th>MinorityPolymer_LDPE1</th>\n",
       "      <th>MinorityPolymer_LLDPE1</th>\n",
       "      <th>MinorityPolymer_PA1</th>\n",
       "      <th>MinorityPolymer_PET1</th>\n",
       "      <th>MinorityPolymer_PP1</th>\n",
       "      <th>MinorityPolymer_PP2</th>\n",
       "      <th>MinorityPolymer_PP3</th>\n",
       "      <th>MinorityPolymer_PS1</th>\n",
       "      <th>MinorityPolymer_PS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Matrix_family  Matrix_crystallinity  Matrix_topology  Matrix_SCB   \n",
       "0              0                     1                0           1  \\\n",
       "1              0                     1                0           1   \n",
       "2              0                     1                0           1   \n",
       "3              0                     1                0           1   \n",
       "4              0                     1                0           1   \n",
       "\n",
       "   Matrix_LCB  Matrix_viscosity  Contaminant_family   \n",
       "0           2                 2                   0  \\\n",
       "1           2                 2                   0   \n",
       "2           2                 2                   0   \n",
       "3           2                 2                   0   \n",
       "4           2                 2                   0   \n",
       "\n",
       "   Contaminant_crystallinity  Contaminant_topology  Contaminant_SCB  ...   \n",
       "0                          2                     1                0  ...  \\\n",
       "1                          2                     1                0  ...   \n",
       "2                          2                     1                0  ...   \n",
       "3                          2                     1                0  ...   \n",
       "4                          2                     1                0  ...   \n",
       "\n",
       "   MinorityPolymer_HDPE1  MinorityPolymer_LDPE1  MinorityPolymer_LLDPE1   \n",
       "0                      1                      0                       0  \\\n",
       "1                      1                      0                       0   \n",
       "2                      1                      0                       0   \n",
       "3                      1                      0                       0   \n",
       "4                      1                      0                       0   \n",
       "\n",
       "   MinorityPolymer_PA1  MinorityPolymer_PET1  MinorityPolymer_PP1   \n",
       "0                    0                     0                    0  \\\n",
       "1                    0                     0                    0   \n",
       "2                    0                     0                    0   \n",
       "3                    0                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   MinorityPolymer_PP2  MinorityPolymer_PP3  MinorityPolymer_PS1   \n",
       "0                    0                    0                    0  \\\n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   MinorityPolymer_PS2  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613887b6",
   "metadata": {},
   "source": [
    "We have 328 instances with 47 features. HOW TO HANDLE THAT MANY ATTRIBUTES WITH SO LITTLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971184b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDPE1 = data[data['MajorityPolymer'] == 'LDPE1']\n",
    "\n",
    "agg = data.groupby('MajorityPolymer').agg('mean')\n",
    "\n",
    "LDPE1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDPE1.head()\n",
    "LDPE1_num = LDPE1[['WeightImpurity', 'POL', 'NOK', 'NOA','matrixE', 'matrixSTRENGTH', 'matrixStrainbreak' , 'matrixImpact', 'impurityE', 'impuritySTRENGTH', 'impurityStrainbreak', 'impurityImpact', 'matrixXc', 'impurityXc' , 'gammaABWu', 'Ddeltad2', 'Ddeltap2', 'Ddeltah2', 'blendE', 'blendSTRENGTH' ,'blendStrainbreak',\n",
    "                'blendImpact','EblendOpEmatrix', 'STRENGTHblendOpSTRENGTHmatrix', 'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'  ]] \n",
    "# hist= plt.hist(LDPE1_num)\n",
    "# LDPE1_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2house2 = data[\"STRENGTHblendOpSTRENGTHmatrix\"][data[\"Matrix_family\"] =='Polyolefin'].iloc[1].item()\n",
    "plt.hist(q2house2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_data = lambda x: x - x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa305ce5",
   "metadata": {},
   "source": [
    "to find the principal all categorical features must be encoded, for such we create dummy vars for the different polymers in the blend. 'HDPE1', 'LLDPE1', 'PP1', 'PP2', 'LDPE1', 'PP3', 'PET1', 'PS1',\n",
    "       'PS2', 'PA1'\n",
    "       \n",
    "       \n",
    "Matriix crystalinity can also be encoded theres low high and amorphous; ORDINAL?? \n",
    "\n",
    "matrix class? donnt know what it means, ['POL', 'POK', 'NOA', 'NOK'] same for contaminant,['POK', 'PURE', 'POL', 'NOK', 'NOA'], then theres class combo which is the combinatio of both of them so it will be droped\n",
    "\n",
    "what are reeks??\n",
    "\n",
    "Topology, \n",
    "PRROBLRMS:\n",
    "SCB has none low high(0,1) and LCB has none and high(0,1,2). is crystalinity ordinal?. \n",
    "\n",
    "how to get the names of the components!!\n",
    "\n",
    "**update 1/5 Anna: \n",
    "\n",
    "EblendOpEmatrix',\n",
    "       'STRENGTHblendOpSTRENGTHmatrix',\n",
    "       'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'. such cols are ratios between the majority plastic and the blend given the feature. \n",
    "       \n",
    "       \n",
    "       'gammaABWu', 'Ddeltad2', 'Ddeltap2', 'Ddeltah2 cols are theoretical estimations that surge then teh classification of the families. thus cols Matrix Class','Impurity Class', 'Class Combo', 'POL', 'POK', 'NOK', 'NOA', are not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Impurity Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Contaminant_viscosity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data\n",
    "# ratio of polymerB \n",
    "d = d.replace({'impurityXc': {'PURE': 0}})\n",
    "\n",
    "#POLYFINE VS NON POLYSINE \n",
    "d = d.replace({'Matrix_family': {'Polyolefin': 0, 'Non-Polyolefin': 1}})\n",
    "d = d.replace({'Contaminant_family': {'Polyolefin': 0, 'Non-Polyolefin': 1}})\n",
    "\n",
    "# Branched or linear topology \n",
    "d = d.replace({'Matrix_topology': {'Branched': 0, 'Linear': 1}})\n",
    "d = d.replace({'Contaminant_topology': {'Branched': 0, 'Linear': 1}})\n",
    "\n",
    "# crystlainity, amorphous shoudl be the lowest \n",
    "d = d.replace({'Matrix_crystallinity': {'Low': 1, 'Amorphous': 0, 'High': 2}})\n",
    "d = d.replace({'Contaminant_crystallinity': {'Low': 1, 'Amorphous': 0, 'High': 2}})\n",
    "\n",
    "# SCB\n",
    "d = d.replace({'Matrix_SCB': {'None': 0, 'High': 1}})\n",
    "d = d.replace({'Contaminant_SCB': {'None': 0, 'High': 1}})\n",
    "\n",
    "# LCB\n",
    "d = d.replace({'Matrix_LCB': {'None': 0, 'Low' :1, 'High': 2}})\n",
    "d = d.replace({'Contaminant_LCB': {'None': 0, 'Low': 1, 'High': 2}})\n",
    "\n",
    "\n",
    "# to be done,encode polymer types of blends and matrix family x2\n",
    "d.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping series number and name and reeks\n",
    "d = d.drop(['NAAM', 'SERIE', 'Reeks' ], axis=1)\n",
    "\n",
    "# theoretical estimations\n",
    "d = d.drop(['gammaABWu', 'Ddeltad2', 'Ddeltap2', 'Ddeltah2'], axis=1)\n",
    "# Kims classes \n",
    "d = d.drop(['Matrix Class','Impurity Class', 'Class Combo', 'POL', 'POK', 'NOK', 'NOA'], axis=1) \n",
    "# ratios \n",
    "d = d.drop(['EblendOpEmatrix', 'STRENGTHblendOpSTRENGTHmatrix',\n",
    "       'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix' ], axis=1)\n",
    "\n",
    "d.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1D = pd.get_dummies(d, columns = ['MajorityPolymer', 'MinorityPolymer', 'Matrix Class', 'Impurity Class'])\n",
    "#only encode the type of polymer\n",
    "h1D = pd.get_dummies(d, columns = ['MajorityPolymer', 'MinorityPolymer'])\n",
    "new_df = h1D.select_dtypes(include=np.number)\n",
    "new_df.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f60dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1D.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVING DATA FILE\n",
    "# h1D.to_csv(\"data_reduced.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4931a3",
   "metadata": {},
   "source": [
    "# PERFORMING PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601afabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_mat2 = np.corrcoef(h1D.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# # Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "# print('Eigenvalues in descending order:')\n",
    "# for i in eig_pairs:\n",
    "#     print(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# th\n",
    "np.round(eig_vals**2 / sum(eig_vals**2), 2)\n",
    "plt.plot(eig_vals**2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4455eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative PCA\n",
    "tot = sum(eig_vals**2)\n",
    "var_exp = [(i**2 / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "# plotting\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(4), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h1D.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0358cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(scale(h1D), index=h1D.index, columns=h1D.columns)\n",
    "pca_loadings = pd.DataFrame(PCA().fit(X).components_.T, index=h1D.columns, columns =h1D.columns.values )\n",
    "d_plot = pd.DataFrame(PCA().fit_transform(X), index = X.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f442ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax1 = plt.subplots(figsize=(9,7))\n",
    "\n",
    "#ax1.set_xlim(-3.5,3.5)\n",
    "#ax1.set_ylim(-3.5,3.5)\n",
    "\n",
    "# Plot Principal Components 1 and 2\n",
    "for i in d_plot.index:\n",
    "    ax1.annotate(i, (d_plot.PC1.loc[i], -d_plot.PC2.loc[i]), ha='center')\n",
    "\n",
    "# Plot reference lines\n",
    "ax1.hlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "ax1.vlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "\n",
    "ax1.set_xlabel('First Principal Component')\n",
    "ax1.set_ylabel('Second Principal Component')\n",
    "    \n",
    "# Plot Principal Component loading vectors, using a second y-axis.\n",
    "ax2 = ax1.twinx().twiny() \n",
    "\n",
    "ax2.set_ylim(-1,1)\n",
    "ax2.set_xlim(-1,1)\n",
    "ax2.tick_params(axis='y', colors='orange')\n",
    "ax2.set_xlabel('Principal Component loading vectors', color='orange')\n",
    "\n",
    "# Plot labels for vectors. Variable 'a' is a small offset parameter to separate arrow tip and text.\n",
    "a = 1.07  \n",
    "for i in pca_loadings[['0', '1']].index:\n",
    "    ax2.annotate(i, (pca_loadings.V1.loc[i]*a, -pca_loadings.V2.loc[i]*a), color='orange')\n",
    "\n",
    "# Plot vectors\n",
    "ax2.arrow(0,0,pca_loadings.V1[0], -pca_loadings.V2[0])\n",
    "ax2.arrow(0,0,pca_loadings.V1[1], -pca_loadings.V2[1])\n",
    "ax2.arrow(0,0,pca_loadings.V1[2], -pca_loadings.V2[2])\n",
    "ax2.arrow(0,0,pca_loadings.V1[3], -pca_loadings.V2[3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08185e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(X)\n",
    "X_cnt = center_data(X)\n",
    "\n",
    "# reducing to 2dim space , only choosoing the best 2 eigenvectors\n",
    "# matrix_w = np.hstack((eig_pairs[0][1].reshape(59,1), \n",
    "#                       eig_pairs[1][1].reshape(59,1),\n",
    "#                       eig_pairs[2][1].reshape(59,1),\n",
    "#                       eig_pairs[3][1].reshape(59,1),\n",
    "#                       eig_pairs[4][1].reshape(59,1)))\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(68,1), \n",
    "                      eig_pairs[1][1].reshape(68,1),\n",
    "                      eig_pairs[2][1].reshape(68,1),\n",
    "                      eig_pairs[3][1].reshape(68,1),\n",
    "                      eig_pairs[4][1].reshape(68,1)))\n",
    "\n",
    "\n",
    "Y = X_std.dot(matrix_w)\n",
    "Xprime = Y.dot(matrix_w.transpose())\n",
    "np.square(Xprime-X_std).mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1786df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT PARAM! \n",
    "# blendE                                 8.227900e+05\n",
    "# blendSTRENGTH                          2.744392e+02\n",
    "# blendStrainbreak                       2.653426e+04\n",
    "# blendImpact                            6.285922e+02\n",
    "# EblendOpEmatrix                        1.796680e+00\n",
    "# STRENGTHblendOpSTRENGTHmatrix          1.899984e-01\n",
    "# StrainbreakblendOpStrainbreakmatrix    1.713696e+02\n",
    "# ImpactblendOpImpactmatrix              1.212540e+01\n",
    "\n",
    "dT = h1D.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact','EblendOpEmatrix','STRENGTHblendOpSTRENGTHmatrix', 'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'], axis=1)\n",
    "#  d.drop(['Class Combo','NAAM', 'SERIE' ], axis=1)\n",
    "yT = h1D[['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact','EblendOpEmatrix','STRENGTHblendOpSTRENGTHmatrix', 'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8395fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pd.DataFrame(scale(dT), index=dT.index, columns=dT.columns)\n",
    "DT = StandardScaler().fit_transform(DT)\n",
    "DT = center_data(DT)\n",
    "\n",
    "cor_mat2 = np.corrcoef(DT.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# reducing to 2dim space , only choosoing the best 4 eigenvectors\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(60,1), \n",
    "                      eig_pairs[1][1].reshape(60,1),\n",
    "                      eig_pairs[2][1].reshape(60,1),\n",
    "                      eig_pairs[3][1].reshape(60,1),\n",
    "                      eig_pairs[4][1].reshape(60,1)))\n",
    "\n",
    "Y = DT.dot(matrix_w)\n",
    "DTprime = Y.dot(matrix_w.transpose())\n",
    "np.square(DTprime-DT).mean(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5981f",
   "metadata": {},
   "source": [
    "# families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF = pd.read_table(\"C:/Users/33789/OneDrive/Desktop/THESIS/data/data_families.csv\", ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68502f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "POK = data[data['Matrix Class'] == 'POK']\n",
    "NOK = data[data['Matrix Class'] == 'NOK']\n",
    "POL = data[data['Matrix Class'] == 'POL']\n",
    "NOA = data[data['Matrix Class'] == 'NOA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9670d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendSTRENGTH',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendE',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendStrainbreak',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")\n",
    "\n",
    "#        'blendSTRENGTH', 'blendStrainbreak', 'blendImpact',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9883d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendImpact',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290d238",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13ebc7",
   "metadata": {},
   "source": [
    "The idea would be to given the majority and minority function of chnage in given property. \n",
    "to min just looking at strength of features;\n",
    "STRENGTH\n",
    "then try the same but not by polymers but families of DR KIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: LDPE B: HDPE STRENGTH\n",
    "# not using one hotenconded data\n",
    "LDPE =d[d['MajorityPolymer']== 'LDPE1']\n",
    "LPDE_HDPE=LDPE[ LDPE['MinorityPolymer']== 'HDPE1']\n",
    "LPDE_HDPET=LPDE_HDPE.iloc[:,2:15]\n",
    "# 16,17 matrix,impurity class; taki,g the order frommatlab code\n",
    "# 21matrix E, 25: I E. 35 E blend= y \n",
    "x = pd.concat([LPDE_HDPET,LPDE_HDPE.iloc[:,21], LPDE_HDPE.iloc[:,25]], axis=1)\n",
    "y = LPDE_HDPE.iloc[:,35]\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(x, y)\n",
    "y_pred = clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x['WeightImpurity'], y, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_pred, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81579792",
   "metadata": {},
   "source": [
    "### trying with POL (A) and B: POK \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POL =h1D[h1D['Matrix Class_POL']== 1]\n",
    "POL_POK=POL[POL['Impurity Class_POK']== 1]\n",
    "POL_POKT=POL_POK.iloc[:,2:15]\n",
    "xF = pd.concat([POL_POKT,POL_POK.iloc[:,21], POL_POK.iloc[:,25]], axis=1)\n",
    "yF = POL_POK.iloc[:,35]\n",
    "sns.histplot( POL_POK['blendE'])\n",
    "sns.histplot(LPDE_HDPE['blendE'])\n",
    "# POL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ead641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(xF, yF)\n",
    "y_pred = clf.predict(xF)\n",
    "plt.plot(xF['WeightImpurity'], yF, marker='o', color='blue')\n",
    "plt.plot(xF['WeightImpurity'], y_pred, marker= 'x',color = 'red', linewidth=1)\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of POL vs POK')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDEP is POK, tryin with HDPE1_PET1 that in NOK\n",
    "HDPE =d[d['MajorityPolymer']== 'HDPE1']\n",
    "HPDE_PET=HDPE[ HDPE['MinorityPolymer']== 'PET1']\n",
    "# training features\n",
    "HPDE_PETT=HPDE_PET.iloc[:,2:15]\n",
    "xF = pd.concat([HPDE_PETT,HPDE_PET.iloc[:,21], HPDE_PET.iloc[:,25]], axis=1)\n",
    "yF = HPDE_PET.iloc[:,35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b513d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(x, y)\n",
    "y_pred = clf.predict(x)\n",
    "plt.plot(x['WeightImpurity'], y, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_pred, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of HPDE_PET')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25269e69",
   "metadata": {},
   "source": [
    "# SVMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e = h1D.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = h1D['blendE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7307d",
   "metadata": {},
   "source": [
    "Such a grouping of data is domain specific. thus IID assumptioon is broken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "#     if train:\n",
    "#         pred = clf.predict(X_train)\n",
    "#         clf_report = pd.DataFrame(r2_score(y_true, y_pred))\n",
    "#         print(\"Train Result:\\n================================================\")\n",
    "#         print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "#     elif train==False:\n",
    "#         pred = clf.predict(X_test)\n",
    "#         clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "#         print(\"Test Result:\\n================================================\")        \n",
    "#         print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(x_e):\n",
    "    print(\"%s %s\" % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ee903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "standardized_data = (h1D - h1D.mean())/ h1D.std()\n",
    "x_e = standardized_data.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = h1D['blendE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "# print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "# print_score(model, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "pipe_steps= [('SVM', SVR())]\n",
    "\n",
    "#TODO: doo same with gaussian\n",
    "params= {\n",
    "    'SVM__C': [0.01, 0.1, 0.5, 1, 10, 100],\n",
    "    'SVM__kernel':['rbf', 'poly', 'linear'],\n",
    "    'SVM__gamma' :[50 ,10 ,5 , 1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001]\n",
    "}\n",
    "pipeline= Pipeline(pipe_steps)\n",
    "# param_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100], \n",
    "#               'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "#               'kernel': ['rbf', 'poly', 'linear']} \n",
    "\n",
    "#grid = GridSearchCV(SVR(), param_grid, refit=True, verbose=1, cv=5)\n",
    "#grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d68754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4 CV \n",
    "# for cv in range(4,6):\n",
    "#     print('entering : -----------------------------------')\n",
    "#     print(cv)\n",
    "#     grid = GridSearchCV(pipeline, param_grid = params, cv=cv)\n",
    "#     grid.fit(X_train, y_train)\n",
    "#     print('scoreefor %d fold CV = %3.2f' %(cv, grid.score(X_test, y_test)))\n",
    "#     print('best param from TD')\n",
    "#     print(grid.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae554993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = [\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [1,0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['poly'],'degree':[0, 2, 4, 6] },\n",
    "#  ]\n",
    "param_grid = [{\n",
    "            'C': [0.001, 0.01, 1, 10], \n",
    "            #   'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "            'gamma': [1,  0.1, 0.001], \n",
    "            'kernel': ['rbf', 'poly', 'linear']\n",
    "              } ]\n",
    "\n",
    "\n",
    "svm = SVR()\n",
    "grid = GridSearchCV(svm, param_grid, cv = 3, scoring = 'neg_mean_absolute_percentage_error', return_train_score = True, verbose = 10 )\n",
    "print('grid done')\n",
    "grid.fit(X_train, y_train)\n",
    "print('fitting done')\n",
    "\n",
    "# n_components = grid.cv_results_[\"C\"]\n",
    "# test_scores = n_components n_components n_components n_components n_components n_components \"kernel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rbf_svr = svm.SVR(kernel='rbf')\n",
    "rbf_svr.fit(x_e, y_e)\n",
    "y_predF = rbf_svr.predict(xF)\n",
    "plt.plot(x_e['WeightImpurity'], y_e, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_predF, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of HPDE_PET')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f9448",
   "metadata": {},
   "source": [
    "DESCRIPTORS OF CHEMISTRY IN ML CAN BE SUPER POWERFUL AND CAN BE ASSESSED BY THEIR IMPORTANCE? THEY CAN ENCAPSULATE NONLINEAR BEHAVOIRS AND PATTERNS IN DATA \n",
    "THEY ARE KNWOLEDGE DRIVEN AND THEN TESTED. \n",
    "FOR THIS EXPERIMENT THAT WE HAVE DIFFERENT FAMILIES AND PROPERTIES TO PREDUCT? IT MAY BE EASIER TO COUNT WITH THEM \n",
    "ELSE KERNEL RIDGE REGRESSION WILL BE NEXT STEP. \n",
    "KERNELSCAN BE SIGMMOID? POLYN? LINEAR? HOW TO FIND THE MOST SUITABLE, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c463da",
   "metadata": {},
   "source": [
    "# filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with new h1D that was redecued alread, first apply contsnat rep$moval variables of variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60871dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only with ELASTICITY, 14? 18? 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e = h1D.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = h1D['blendE']\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeea56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forthe moment stratify in E to insure that all values of E are in all sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38cf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying for QUASIconstant filter because constant returned 0\n",
    "constant_filter = VarianceThreshold(threshold=0.1)\n",
    "constant_filter.fit(X_train)\n",
    "VarianceThreshold(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af22f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_filter.get_support().sum()\n",
    "constant_list = [not temp for temp in constant_filter.get_support()]\n",
    "x_e.columns[constant_list]\n",
    "# NONE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629f80c",
   "metadata": {},
   "source": [
    "whne threshold =0.1, these are the cols quasi constant: 'WeightImpurity', 'MajorityPolymer_PA1', 'MajorityPolymer_PET1',\n",
    "       'MajorityPolymer_PP1', 'MajorityPolymer_PP2', 'MajorityPolymer_PP3',\n",
    "       'MajorityPolymer_PS2', 'MinorityPolymer_LLDPE1', 'MinorityPolymer_PA1',\n",
    "       'MinorityPolymer_PP2', 'MinorityPolymer_PP3', 'MinorityPolymer_PS2'\n",
    "       \n",
    "       meaning the ratio of impurity; and the Mayority and minority polymer are not that relevant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a66f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filter = constant_filter.transform(X_train)\n",
    "X_test_filter = constant_filter.transform(X_test)\n",
    "X_train_filter.shape, X_test_filter.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f5d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec2b41b",
   "metadata": {},
   "source": [
    "**Pearsons Correlation\n",
    "from filetring apply corr for every col with target and find most avalauble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a90dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b190f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}