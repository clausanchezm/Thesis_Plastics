{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca79881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import os \n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3863b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea98824",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataE = pd.read_excel('data/Dataset_May2022_RD.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccb917e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.getcwd() + '/data/data_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcdd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matrix_family</th>\n",
       "      <th>Matrix_crystallinity</th>\n",
       "      <th>Matrix_topology</th>\n",
       "      <th>Matrix_SCB</th>\n",
       "      <th>Matrix_LCB</th>\n",
       "      <th>Matrix_viscosity</th>\n",
       "      <th>Contaminant_family</th>\n",
       "      <th>Contaminant_crystallinity</th>\n",
       "      <th>Contaminant_topology</th>\n",
       "      <th>Contaminant_SCB</th>\n",
       "      <th>...</th>\n",
       "      <th>MinorityPolymer_HDPE1</th>\n",
       "      <th>MinorityPolymer_LDPE1</th>\n",
       "      <th>MinorityPolymer_LLDPE1</th>\n",
       "      <th>MinorityPolymer_PA1</th>\n",
       "      <th>MinorityPolymer_PET1</th>\n",
       "      <th>MinorityPolymer_PP1</th>\n",
       "      <th>MinorityPolymer_PP2</th>\n",
       "      <th>MinorityPolymer_PP3</th>\n",
       "      <th>MinorityPolymer_PS1</th>\n",
       "      <th>MinorityPolymer_PS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Matrix_family  Matrix_crystallinity  Matrix_topology  Matrix_SCB   \n",
       "0              0                     1                0           1  \\\n",
       "1              0                     1                0           1   \n",
       "2              0                     1                0           1   \n",
       "3              0                     1                0           1   \n",
       "4              0                     1                0           1   \n",
       "\n",
       "   Matrix_LCB  Matrix_viscosity  Contaminant_family   \n",
       "0           2                 2                   0  \\\n",
       "1           2                 2                   0   \n",
       "2           2                 2                   0   \n",
       "3           2                 2                   0   \n",
       "4           2                 2                   0   \n",
       "\n",
       "   Contaminant_crystallinity  Contaminant_topology  Contaminant_SCB  ...   \n",
       "0                          2                     1                0  ...  \\\n",
       "1                          2                     1                0  ...   \n",
       "2                          2                     1                0  ...   \n",
       "3                          2                     1                0  ...   \n",
       "4                          2                     1                0  ...   \n",
       "\n",
       "   MinorityPolymer_HDPE1  MinorityPolymer_LDPE1  MinorityPolymer_LLDPE1   \n",
       "0                      1                      0                       0  \\\n",
       "1                      1                      0                       0   \n",
       "2                      1                      0                       0   \n",
       "3                      1                      0                       0   \n",
       "4                      1                      0                       0   \n",
       "\n",
       "   MinorityPolymer_PA1  MinorityPolymer_PET1  MinorityPolymer_PP1   \n",
       "0                    0                     0                    0  \\\n",
       "1                    0                     0                    0   \n",
       "2                    0                     0                    0   \n",
       "3                    0                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   MinorityPolymer_PP2  MinorityPolymer_PP3  MinorityPolymer_PS1   \n",
       "0                    0                    0                    0  \\\n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   MinorityPolymer_PS2  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613887b6",
   "metadata": {},
   "source": [
    "We have 328 instances with 47 features. HOW TO HANDLE THAT MANY ATTRIBUTES WITH SO LITTLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2house2 = data[\"STRENGTHblendOpSTRENGTHmatrix\"][data[\"Matrix_family\"] =='Polyolefin'].iloc[1].item()\n",
    "plt.hist(q2house2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_data = lambda x: x - x.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa305ce5",
   "metadata": {},
   "source": [
    "to find the principal all categorical features must be encoded, for such we create dummy vars for the different polymers in the blend. 'HDPE1', 'LLDPE1', 'PP1', 'PP2', 'LDPE1', 'PP3', 'PET1', 'PS1',\n",
    "       'PS2', 'PA1'\n",
    "       \n",
    "       \n",
    "Matriix crystalinity can also be encoded theres low high and amorphous; ORDINAL?? \n",
    "\n",
    "matrix class? donnt know what it means, ['POL', 'POK', 'NOA', 'NOK'] same for contaminant,['POK', 'PURE', 'POL', 'NOK', 'NOA'], then theres class combo which is the combinatio of both of them so it will be droped\n",
    "\n",
    "what are reeks??\n",
    "\n",
    "Topology, \n",
    "PRROBLRMS:\n",
    "SCB has none low high(0,1) and LCB has none and high(0,1,2). is crystalinity ordinal?. \n",
    "\n",
    "how to get the names of the components!!\n",
    "\n",
    "**update 1/5 Anna: \n",
    "\n",
    "EblendOpEmatrix',\n",
    "       'STRENGTHblendOpSTRENGTHmatrix',\n",
    "       'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'. such cols are ratios between the majority plastic and the blend given the feature. \n",
    "       \n",
    "       \n",
    "       'gammaABWu', 'Ddeltad2', 'Ddeltap2', 'Ddeltah2 cols are theoretical estimations that surge then teh classification of the families. thus cols Matrix Class','Impurity Class', 'Class Combo', 'POL', 'POK', 'NOK', 'NOA', are not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Impurity Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Contaminant_viscosity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e9a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reeks', 'NAAM', 'SERIE', 'MajorityPolymer', 'MinorityPolymer',\n",
       "       'Matrix_family', 'Matrix_crystallinity', 'Matrix_topology',\n",
       "       'Matrix_SCB', 'Matrix_LCB', 'Matrix_viscosity',\n",
       "       'Contaminant_family', 'Contaminant_crystallinity',\n",
       "       'Contaminant_topology', 'Contaminant_SCB', 'Contaminant_LCB',\n",
       "       'Contaminant_viscosity', 'WeightImpurity', 'Matrix Class',\n",
       "       'Impurity Class', 'Class Combo', 'POL', 'POK', 'NOK', 'NOA',\n",
       "       'matrixE', 'matrixSTRENGTH', 'matrixStrainbreak', 'matrixImpact',\n",
       "       'impurityE', 'impuritySTRENGTH', 'impurityStrainbreak',\n",
       "       'impurityImpact', 'matrixXc', 'impurityXc', 'gammaABWu',\n",
       "       'Ddeltad2', 'Ddeltap2', 'Ddeltah2', 'blendE', 'blendSTRENGTH',\n",
       "       'blendStrainbreak', 'blendImpact', 'EblendOpEmatrix',\n",
       "       'STRENGTHblendOpSTRENGTHmatrix',\n",
       "       'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dataE\n",
    "# ratio of polymerB \n",
    "d = d.replace({'impurityXc': {'PURE': 0}})\n",
    "\n",
    "#POLYFINE VS NON POLYSINE \n",
    "d = d.replace({'Matrix_family': {'Polyolefin': 0, 'Non-Polyolefin': 1}})\n",
    "d = d.replace({'Contaminant_family': {'Polyolefin': 0, 'Non-Polyolefin': 1}})\n",
    "\n",
    "# Branched or linear topology \n",
    "d = d.replace({'Matrix_topology': {'Branched': 0, 'Linear': 1}})\n",
    "d = d.replace({'Contaminant_topology': {'Branched': 0, 'Linear': 1}})\n",
    "\n",
    "# crystlainity, amorphous shoudl be the lowest \n",
    "d = d.replace({'Matrix_crystallinity': {'Low': 1, 'Amorphous': 0, 'High': 2}})\n",
    "d = d.replace({'Contaminant_crystallinity': {'Low': 1, 'Amorphous': 0, 'High': 2}})\n",
    "\n",
    "# SCB\n",
    "d = d.replace({'Matrix_SCB': {'None': 0, 'High': 1}})\n",
    "d = d.replace({'Contaminant_SCB': {'None': 0, 'High': 1}})\n",
    "\n",
    "# LCB\n",
    "d = d.replace({'Matrix_LCB': {'None': 0, 'Low' :1, 'High': 2}})\n",
    "d = d.replace({'Contaminant_LCB': {'None': 0, 'Low': 1, 'High': 2}})\n",
    "\n",
    "\n",
    "# to be done,encode polymer types of blends and matrix family x2\n",
    "d.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d42909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MajorityPolymer', 'MinorityPolymer', 'Matrix_family',\n",
       "       'Matrix_crystallinity', 'Matrix_topology', 'Matrix_SCB',\n",
       "       'Matrix_LCB', 'Matrix_viscosity', 'Contaminant_family',\n",
       "       'Contaminant_crystallinity', 'Contaminant_topology',\n",
       "       'Contaminant_SCB', 'Contaminant_LCB', 'Contaminant_viscosity',\n",
       "       'WeightImpurity', 'matrixE', 'matrixSTRENGTH', 'matrixStrainbreak',\n",
       "       'matrixImpact', 'impurityE', 'impuritySTRENGTH',\n",
       "       'impurityStrainbreak', 'impurityImpact', 'matrixXc', 'impurityXc',\n",
       "       'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping series number and name and reeks\n",
    "d = d.drop(['NAAM', 'SERIE', 'Reeks' ], axis=1)\n",
    "\n",
    "# theoretical estimations\n",
    "d = d.drop(['gammaABWu', 'Ddeltad2', 'Ddeltap2', 'Ddeltah2'], axis=1)\n",
    "# Kims classes \n",
    "d = d.drop(['Matrix Class','Impurity Class', 'Class Combo', 'POL', 'POK', 'NOK', 'NOA'], axis=1) \n",
    "# ratios \n",
    "d = d.drop(['EblendOpEmatrix', 'STRENGTHblendOpSTRENGTHmatrix',\n",
    "       'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix' ], axis=1)\n",
    "\n",
    "d.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0529a075",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['MajorityPolymer', 'MinorityPolymer'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# h1D = pd.get_dummies(d, columns = ['MajorityPolymer', 'MinorityPolymer', 'Matrix Class', 'Impurity Class'])\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#only encode the type of polymer\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m h1D \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dummies\u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMajorityPolymer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMinorityPolymer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m new_df \u001B[38;5;241m=\u001B[39m h1D\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mnumber)\n\u001B[0;32m      5\u001B[0m new_df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:890\u001B[0m, in \u001B[0;36mget_dummies\u001B[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001B[0m\n\u001B[0;32m    888\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput must be a list-like for parameter `columns`\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    889\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 890\u001B[0m     data_to_encode \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001B[39;00m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_len\u001B[39m(item, name):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3464\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3462\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3463\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3464\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3466\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1314\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1311\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1312\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m ax\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 1314\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_read_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m needs_i8_conversion(ax\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m   1317\u001B[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001B[0;32m   1318\u001B[0m ):\n\u001B[0;32m   1319\u001B[0m     \u001B[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001B[39;00m\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001B[39;00m\n\u001B[0;32m   1321\u001B[0m     keyarr \u001B[38;5;241m=\u001B[39m ax\u001B[38;5;241m.\u001B[39mtake(indexer)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1374\u001B[0m, in \u001B[0;36m_LocIndexer._validate_read_indexer\u001B[1;34m(self, key, indexer, axis)\u001B[0m\n\u001B[0;32m   1372\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[0;32m   1373\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 1374\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1376\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['MajorityPolymer', 'MinorityPolymer'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# h1D = pd.get_dummies(d, columns = ['MajorityPolymer', 'MinorityPolymer', 'Matrix Class', 'Impurity Class'])\n",
    "#only encode the type of polymer\n",
    "h1D = pd.get_dummies(d, columns = ['MajorityPolymer', 'MinorityPolymer'])\n",
    "new_df = h1D.select_dtypes(include=np.number)\n",
    "new_df.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f60dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1D.columns.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561aafc7",
   "metadata": {},
   "source": [
    "## PARTITIONING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55892d0",
   "metadata": {},
   "source": [
    "by matrix family: P or NP \n",
    "by type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f03e9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# family . \n",
    "P = data[data['Matrix_family']== 0]\n",
    "NP = data[data['Matrix_family']== 1]\n",
    "\n",
    "NP.count().get(0) + P.count().get(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb78e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "d['MajorityPolymer'].unique()\n",
    "\n",
    "LDPE1 = d[d['MajorityPolymer']== 'LDPE1']\n",
    "HDPE1 = d[d['MajorityPolymer']== 'HDPE1']\n",
    "LLDPE1 = d[d['MajorityPolymer']== 'LLDPE1']\n",
    "PET1 = d[d['MajorityPolymer']== 'PET1']\n",
    "\n",
    "PS1 = d[d['MajorityPolymer']== 'PS1']\n",
    "PS2 = d[d['MajorityPolymer']== 'PS2']\n",
    "\n",
    "PP1 = d[d['MajorityPolymer']== 'PP1']\n",
    "PP2 = d[d['MajorityPolymer']== 'PP2']\n",
    "PP3 = d[d['MajorityPolymer']== 'PP3']\n",
    "\n",
    "PA1 = d[d['MajorityPolymer']== 'PA1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bb391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDPE1.count().get(0) + LLDPE1.count().get(0) + HDPE1.count().get(0) +PET1.count().get(0) + PS1.count().get(0) +PS2.count().get(0)+ PA1.count().get(0)+ PP1.count().get(0)+PP2.count().get(0)+ PP3.count().get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c236bdac",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:/Users/33789/OneDrive/Desktop/THESIS/data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# # SAVING DATA FILE into local \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# folder_to_export_path = \"C:/Users/33789/OneDrive/Desktop/THESIS/data/\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m folder_to_export_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:/Users/33789/OneDrive/Desktop/THESIS/data/data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mLDPE1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder_to_export_path\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata_reduced_ldpe.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m HDPE1\u001B[38;5;241m.\u001B[39mto_csv(folder_to_export_path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_reduced_hdpe.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m LLDPE1\u001B[38;5;241m.\u001B[39mto_csv(folder_to_export_path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata_reduced_lldpe.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:3772\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[1;32m   3761\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[1;32m   3763\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[1;32m   3764\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[1;32m   3765\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3769\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[1;32m   3770\u001B[0m )\n\u001B[0;32m-> 3772\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3773\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3774\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3775\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3776\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3777\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3778\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3779\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3780\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3782\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/formats/format.py:1186\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[1;32m   1165\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[1;32m   1168\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[1;32m   1169\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1184\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[1;32m   1185\u001B[0m )\n\u001B[0;32m-> 1186\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[1;32m   1189\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/formats/csvs.py:240\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[0;32m--> 240\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[1;32m    250\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m    251\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    256\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[1;32m    257\u001B[0m     )\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:737\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    735\u001B[0m \u001B[38;5;66;03m# Only for write methods\u001B[39;00m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m is_path:\n\u001B[0;32m--> 737\u001B[0m     \u001B[43mcheck_parent_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compression:\n\u001B[1;32m    740\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzstd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    741\u001B[0m         \u001B[38;5;66;03m# compression libraries do not like an explicit text-mode\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:600\u001B[0m, in \u001B[0;36mcheck_parent_directory\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m    598\u001B[0m parent \u001B[38;5;241m=\u001B[39m Path(path)\u001B[38;5;241m.\u001B[39mparent\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m parent\u001B[38;5;241m.\u001B[39mis_dir():\n\u001B[0;32m--> 600\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot save file into a non-existent directory: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mOSError\u001B[0m: Cannot save file into a non-existent directory: 'C:/Users/33789/OneDrive/Desktop/THESIS/data'"
     ]
    }
   ],
   "source": [
    "# # SAVING DATA FILE into local \n",
    "# folder_to_export_path = \"C:/Users/33789/OneDrive/Desktop/THESIS/data/\"\n",
    "folder_to_export_path = \"C:/Users/33789/OneDrive/Desktop/THESIS/data/data\"\n",
    "LDPE1.to_csv(folder_to_export_path+'data_reduced_ldpe.csv', index=False)\n",
    "HDPE1.to_csv(folder_to_export_path+'data_reduced_hdpe.csv', index=False)\n",
    "LLDPE1.to_csv(folder_to_export_path+'data_reduced_lldpe.csv', index=False)\n",
    "PET1.to_csv(folder_to_export_path+'data_reduced_pet.csv', index=False)\n",
    "PS1.to_csv(folder_to_export_path+'data_reduced_ps1.csv', index=False)\n",
    "PS2.to_csv(folder_to_export_path+'data_reduced_ps2.csv', index=False)\n",
    "PP1.to_csv(folder_to_export_path+'data_reduced_pp1.csv', index=False)\n",
    "PP2.to_csv(folder_to_export_path+'data_reduced_pp2.csv', index=False)\n",
    "PP3.to_csv(folder_to_export_path+'data_reduced_pp3.csv', index=False)\n",
    "PA1.to_csv(folder_to_export_path+'data_reduced_pa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4931a3",
   "metadata": {},
   "source": [
    "# PERFORMING PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601afabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_mat2 = np.corrcoef(h1D.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# # Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "# print('Eigenvalues in descending order:')\n",
    "# for i in eig_pairs:\n",
    "#     print(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# th\n",
    "np.round(eig_vals**2 / sum(eig_vals**2), 2)\n",
    "plt.plot(eig_vals**2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4455eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative PCA\n",
    "tot = sum(eig_vals**2)\n",
    "var_exp = [(i**2 / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "# plotting\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(4), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h1D.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0358cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(scale(h1D), index=h1D.index, columns=h1D.columns)\n",
    "pca_loadings = pd.DataFrame(PCA().fit(X).components_.T, index=h1D.columns, columns =h1D.columns.values )\n",
    "d_plot = pd.DataFrame(PCA().fit_transform(X), index = X.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f442ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax1 = plt.subplots(figsize=(9,7))\n",
    "\n",
    "#ax1.set_xlim(-3.5,3.5)\n",
    "#ax1.set_ylim(-3.5,3.5)\n",
    "\n",
    "# Plot Principal Components 1 and 2\n",
    "for i in d_plot.index:\n",
    "    ax1.annotate(i, (d_plot.PC1.loc[i], -d_plot.PC2.loc[i]), ha='center')\n",
    "\n",
    "# Plot reference lines\n",
    "ax1.hlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "ax1.vlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "\n",
    "ax1.set_xlabel('First Principal Component')\n",
    "ax1.set_ylabel('Second Principal Component')\n",
    "    \n",
    "# Plot Principal Component loading vectors, using a second y-axis.\n",
    "ax2 = ax1.twinx().twiny() \n",
    "\n",
    "ax2.set_ylim(-1,1)\n",
    "ax2.set_xlim(-1,1)\n",
    "ax2.tick_params(axis='y', colors='orange')\n",
    "ax2.set_xlabel('Principal Component loading vectors', color='orange')\n",
    "\n",
    "# Plot labels for vectors. Variable 'a' is a small offset parameter to separate arrow tip and text.\n",
    "a = 1.07  \n",
    "for i in pca_loadings[['0', '1']].index:\n",
    "    ax2.annotate(i, (pca_loadings.V1.loc[i]*a, -pca_loadings.V2.loc[i]*a), color='orange')\n",
    "\n",
    "# Plot vectors\n",
    "ax2.arrow(0,0,pca_loadings.V1[0], -pca_loadings.V2[0])\n",
    "ax2.arrow(0,0,pca_loadings.V1[1], -pca_loadings.V2[1])\n",
    "ax2.arrow(0,0,pca_loadings.V1[2], -pca_loadings.V2[2])\n",
    "ax2.arrow(0,0,pca_loadings.V1[3], -pca_loadings.V2[3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08185e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = StandardScaler().fit_transform(X)\n",
    "X_cnt = center_data(X)\n",
    "\n",
    "# reducing to 2dim space , only choosoing the best 2 eigenvectors\n",
    "# matrix_w = np.hstack((eig_pairs[0][1].reshape(59,1), \n",
    "#                       eig_pairs[1][1].reshape(59,1),\n",
    "#                       eig_pairs[2][1].reshape(59,1),\n",
    "#                       eig_pairs[3][1].reshape(59,1),\n",
    "#                       eig_pairs[4][1].reshape(59,1)))\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(68,1), \n",
    "                      eig_pairs[1][1].reshape(68,1),\n",
    "                      eig_pairs[2][1].reshape(68,1),\n",
    "                      eig_pairs[3][1].reshape(68,1),\n",
    "                      eig_pairs[4][1].reshape(68,1)))\n",
    "\n",
    "\n",
    "Y = X_std.dot(matrix_w)\n",
    "Xprime = Y.dot(matrix_w.transpose())\n",
    "np.square(Xprime-X_std).mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1786df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT PARAM! \n",
    "# blendE                                 8.227900e+05\n",
    "# blendSTRENGTH                          2.744392e+02\n",
    "# blendStrainbreak                       2.653426e+04\n",
    "# blendImpact                            6.285922e+02\n",
    "# EblendOpEmatrix                        1.796680e+00\n",
    "# STRENGTHblendOpSTRENGTHmatrix          1.899984e-01\n",
    "# StrainbreakblendOpStrainbreakmatrix    1.713696e+02\n",
    "# ImpactblendOpImpactmatrix              1.212540e+01\n",
    "\n",
    "dT = h1D.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact','EblendOpEmatrix','STRENGTHblendOpSTRENGTHmatrix', 'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix'], axis=1)\n",
    "#  d.drop(['Class Combo','NAAM', 'SERIE' ], axis=1)\n",
    "yT = h1D[['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact','EblendOpEmatrix','STRENGTHblendOpSTRENGTHmatrix', 'StrainbreakblendOpStrainbreakmatrix', 'ImpactblendOpImpactmatrix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8395fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pd.DataFrame(scale(dT), index=dT.index, columns=dT.columns)\n",
    "DT = StandardScaler().fit_transform(DT)\n",
    "DT = center_data(DT)\n",
    "\n",
    "cor_mat2 = np.corrcoef(DT.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# reducing to 2dim space , only choosoing the best 4 eigenvectors\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(60,1), \n",
    "                      eig_pairs[1][1].reshape(60,1),\n",
    "                      eig_pairs[2][1].reshape(60,1),\n",
    "                      eig_pairs[3][1].reshape(60,1),\n",
    "                      eig_pairs[4][1].reshape(60,1)))\n",
    "\n",
    "Y = DT.dot(matrix_w)\n",
    "DTprime = Y.dot(matrix_w.transpose())\n",
    "np.square(DTprime-DT).mean(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5981f",
   "metadata": {},
   "source": [
    "# families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF = pd.read_table(\"C:/Users/33789/OneDrive/Desktop/THESIS/data/data_families.csv\", ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68502f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "POK = data[data['Matrix Class'] == 'POK']\n",
    "NOK = data[data['Matrix Class'] == 'NOK']\n",
    "POL = data[data['Matrix Class'] == 'POL']\n",
    "NOA = data[data['Matrix Class'] == 'NOA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9670d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendSTRENGTH',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendE',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendStrainbreak',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")\n",
    "\n",
    "#        'blendSTRENGTH', 'blendStrainbreak', 'blendImpact',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9883d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=data, x='WeightImpurity', y='blendImpact',\n",
    "    col=\"Matrix Class\", hue=\"Impurity Class\", \n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290d238",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a13ebc7",
   "metadata": {},
   "source": [
    "The idea would be to given the majority and minority function of chnage in given property. \n",
    "to min just looking at strength of features;\n",
    "STRENGTH\n",
    "then try the same but not by polymers but families of DR KIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: LDPE B: HDPE STRENGTH\n",
    "# not using one hotenconded data\n",
    "LDPE =d[d['MajorityPolymer']== 'LDPE1']\n",
    "LPDE_HDPE=LDPE[ LDPE['MinorityPolymer']== 'HDPE1']\n",
    "LPDE_HDPET=LPDE_HDPE.iloc[:,2:15]\n",
    "# 16,17 matrix,impurity class; taki,g the order frommatlab code\n",
    "# 21matrix E, 25: I E. 35 E blend= y \n",
    "x = pd.concat([LPDE_HDPET,LPDE_HDPE.iloc[:,21], LPDE_HDPE.iloc[:,25]], axis=1)\n",
    "y = LPDE_HDPE.iloc[:,35]\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(x, y)\n",
    "y_pred = clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x['WeightImpurity'], y, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_pred, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81579792",
   "metadata": {},
   "source": [
    "### trying with POL (A) and B: POK \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POL =h1D[h1D['Matrix Class_POL']== 1]\n",
    "POL_POK=POL[POL['Impurity Class_POK']== 1]\n",
    "POL_POKT=POL_POK.iloc[:,2:15]\n",
    "xF = pd.concat([POL_POKT,POL_POK.iloc[:,21], POL_POK.iloc[:,25]], axis=1)\n",
    "yF = POL_POK.iloc[:,35]\n",
    "sns.histplot( POL_POK['blendE'])\n",
    "sns.histplot(LPDE_HDPE['blendE'])\n",
    "# POL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ead641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(xF, yF)\n",
    "y_pred = clf.predict(xF)\n",
    "plt.plot(xF['WeightImpurity'], yF, marker='o', color='blue')\n",
    "plt.plot(xF['WeightImpurity'], y_pred, marker= 'x',color = 'red', linewidth=1)\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of POL vs POK')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDEP is POK, tryin with HDPE1_PET1 that in NOK\n",
    "HDPE =d[d['MajorityPolymer']== 'HDPE1']\n",
    "HPDE_PET=HDPE[ HDPE['MinorityPolymer']== 'PET1']\n",
    "# training features\n",
    "HPDE_PETT=HPDE_PET.iloc[:,2:15]\n",
    "xF = pd.concat([HPDE_PETT,HPDE_PET.iloc[:,21], HPDE_PET.iloc[:,25]], axis=1)\n",
    "yF = HPDE_PET.iloc[:,35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b513d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianProcessRegressor()\n",
    "clf.fit(x, y)\n",
    "y_pred = clf.predict(x)\n",
    "plt.plot(x['WeightImpurity'], y, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_pred, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of HPDE_PET')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25269e69",
   "metadata": {},
   "source": [
    "# SVMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e = h1D.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = h1D['blendE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7307d",
   "metadata": {},
   "source": [
    "Such a grouping of data is domain specific. thus IID assumptioon is broken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "#     if train:\n",
    "#         pred = clf.predict(X_train)\n",
    "#         clf_report = pd.DataFrame(r2_score(y_true, y_pred))\n",
    "#         print(\"Train Result:\\n================================================\")\n",
    "#         print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "#     elif train==False:\n",
    "#         pred = clf.predict(X_test)\n",
    "#         clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "#         print(\"Test Result:\\n================================================\")        \n",
    "#         print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "#         print(\"_______________________________________________\")\n",
    "#         print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(x_e):\n",
    "    print(\"%s %s\" % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ee903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "standardized_data = (h1D - h1D.mean())/ h1D.std()\n",
    "x_e = standardized_data.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = h1D['blendE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "# print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "# print_score(model, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "pipe_steps= [('SVM', SVR())]\n",
    "\n",
    "#TODO: doo same with gaussian\n",
    "params= {\n",
    "    'SVM__C': [0.01, 0.1, 0.5, 1, 10, 100],\n",
    "    'SVM__kernel':['rbf', 'poly', 'linear'],\n",
    "    'SVM__gamma' :[50 ,10 ,5 , 1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001]\n",
    "}\n",
    "pipeline= Pipeline(pipe_steps)\n",
    "# param_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100], \n",
    "#               'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "#               'kernel': ['rbf', 'poly', 'linear']} \n",
    "\n",
    "#grid = GridSearchCV(SVR(), param_grid, refit=True, verbose=1, cv=5)\n",
    "#grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d68754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4 CV \n",
    "# for cv in range(4,6):\n",
    "#     print('entering : -----------------------------------')\n",
    "#     print(cv)\n",
    "#     grid = GridSearchCV(pipeline, param_grid = params, cv=cv)\n",
    "#     grid.fit(X_train, y_train)\n",
    "#     print('scoreefor %d fold CV = %3.2f' %(cv, grid.score(X_test, y_test)))\n",
    "#     print('best param from TD')\n",
    "#     print(grid.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae554993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# param_grid = [\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [1,0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#   {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'kernel': ['poly'],'degree':[0, 2, 4, 6] },\n",
    "#  ]\n",
    "param_grid = [{\n",
    "            'C': [0.001, 0.01, 1, 10], \n",
    "            #   'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "            'gamma': [1,  0.1, 0.001], \n",
    "            'kernel': ['rbf', 'poly', 'linear']\n",
    "              } ]\n",
    "\n",
    "\n",
    "svm = SVR()\n",
    "grid = GridSearchCV(svm, param_grid, cv = 3, scoring = 'neg_mean_absolute_percentage_error', return_train_score = True, verbose = 10 )\n",
    "print('grid done')\n",
    "grid.fit(X_train, y_train)\n",
    "print('fitting done')\n",
    "\n",
    "# n_components = grid.cv_results_[\"C\"]\n",
    "# test_scores = n_components n_components n_components n_components n_components n_components \"kernel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rbf_svr = svm.SVR(kernel='rbf')\n",
    "rbf_svr.fit(x_e, y_e)\n",
    "y_predF = rbf_svr.predict(xF)\n",
    "plt.plot(x_e['WeightImpurity'], y_e, marker='o', color='blue')\n",
    "plt.plot(x['WeightImpurity'], y_predF, marker= 'x',color = 'red')\n",
    "plt.xlabel(\"ratio impurity\")\n",
    "plt.ylabel(\"Elasticity\")\n",
    "plt.title('Elasticity of HPDE_PET')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f9448",
   "metadata": {},
   "source": [
    "DESCRIPTORS OF CHEMISTRY IN ML CAN BE SUPER POWERFUL AND CAN BE ASSESSED BY THEIR IMPORTANCE? THEY CAN ENCAPSULATE NONLINEAR BEHAVOIRS AND PATTERNS IN DATA \n",
    "THEY ARE KNWOLEDGE DRIVEN AND THEN TESTED. \n",
    "FOR THIS EXPERIMENT THAT WE HAVE DIFFERENT FAMILIES AND PROPERTIES TO PREDUCT? IT MAY BE EASIER TO COUNT WITH THEM \n",
    "ELSE KERNEL RIDGE REGRESSION WILL BE NEXT STEP. \n",
    "KERNELSCAN BE SIGMMOID? POLYN? LINEAR? HOW TO FIND THE MOST SUITABLE, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c463da",
   "metadata": {},
   "source": [
    "# filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with new h1D that was redecued alread, first apply contsnat rep$moval variables of variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0011118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60871dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only with ELASTICITY, 14? 18? 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0542e420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matrix_family</th>\n",
       "      <th>Matrix_crystallinity</th>\n",
       "      <th>Matrix_topology</th>\n",
       "      <th>Matrix_SCB</th>\n",
       "      <th>Matrix_LCB</th>\n",
       "      <th>Matrix_viscosity</th>\n",
       "      <th>Contaminant_family</th>\n",
       "      <th>Contaminant_crystallinity</th>\n",
       "      <th>Contaminant_topology</th>\n",
       "      <th>Contaminant_SCB</th>\n",
       "      <th>...</th>\n",
       "      <th>MinorityPolymer_HDPE1</th>\n",
       "      <th>MinorityPolymer_LDPE1</th>\n",
       "      <th>MinorityPolymer_LLDPE1</th>\n",
       "      <th>MinorityPolymer_PA1</th>\n",
       "      <th>MinorityPolymer_PET1</th>\n",
       "      <th>MinorityPolymer_PP1</th>\n",
       "      <th>MinorityPolymer_PP2</th>\n",
       "      <th>MinorityPolymer_PP3</th>\n",
       "      <th>MinorityPolymer_PS1</th>\n",
       "      <th>MinorityPolymer_PS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Matrix_family  Matrix_crystallinity  Matrix_topology  Matrix_SCB  \\\n",
       "0              0                     1                0           1   \n",
       "1              0                     1                0           1   \n",
       "2              0                     1                0           1   \n",
       "3              0                     1                0           1   \n",
       "4              0                     1                0           1   \n",
       "\n",
       "   Matrix_LCB  Matrix_viscosity  Contaminant_family  \\\n",
       "0           2                 2                   0   \n",
       "1           2                 2                   0   \n",
       "2           2                 2                   0   \n",
       "3           2                 2                   0   \n",
       "4           2                 2                   0   \n",
       "\n",
       "   Contaminant_crystallinity  Contaminant_topology  Contaminant_SCB  ...  \\\n",
       "0                          2                     1                0  ...   \n",
       "1                          2                     1                0  ...   \n",
       "2                          2                     1                0  ...   \n",
       "3                          2                     1                0  ...   \n",
       "4                          2                     1                0  ...   \n",
       "\n",
       "   MinorityPolymer_HDPE1  MinorityPolymer_LDPE1  MinorityPolymer_LLDPE1  \\\n",
       "0                      1                      0                       0   \n",
       "1                      1                      0                       0   \n",
       "2                      1                      0                       0   \n",
       "3                      1                      0                       0   \n",
       "4                      1                      0                       0   \n",
       "\n",
       "   MinorityPolymer_PA1  MinorityPolymer_PET1  MinorityPolymer_PP1  \\\n",
       "0                    0                     0                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    0                     0                    0   \n",
       "3                    0                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   MinorityPolymer_PP2  MinorityPolymer_PP3  MinorityPolymer_PS1  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   MinorityPolymer_PS2  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_e = h1D.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "#        'matrixImpact','impuritySTRENGTH',\n",
    "#        'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "# y_e = h1D['blendE']\n",
    "x_e = data.drop(['matrixSTRENGTH', 'matrixStrainbreak',\n",
    "       'matrixImpact','impuritySTRENGTH',\n",
    "       'impurityStrainbreak', 'impurityImpact', 'blendE', 'blendSTRENGTH', 'blendStrainbreak', 'blendImpact'], axis =1)\n",
    "y_e = data['blendE']\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edeea56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forthe moment stratify in E to insure that all values of E are in all sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_e, y_e, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38cf527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying for QUASIconstant filter because constant returned 0\n",
    "constant_filter = VarianceThreshold(threshold=0.1)\n",
    "constant_filter.fit(X_train)\n",
    "VarianceThreshold(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af22f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WeightImpurity', 'MajorityPolymer_PA1', 'MajorityPolymer_PET1',\n",
       "       'MajorityPolymer_PP1', 'MajorityPolymer_PP2', 'MajorityPolymer_PP3',\n",
       "       'MajorityPolymer_PS2', 'MinorityPolymer_LLDPE1', 'MinorityPolymer_PA1',\n",
       "       'MinorityPolymer_PP2', 'MinorityPolymer_PP3', 'MinorityPolymer_PS2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_filter.get_support().sum()\n",
    "constant_list = [not temp for temp in constant_filter.get_support()]\n",
    "x_e.columns[constant_list]\n",
    "# NONE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629f80c",
   "metadata": {},
   "source": [
    "whne threshold =0.1, these are the cols quasi constant: 'WeightImpurity', 'MajorityPolymer_PA1', 'MajorityPolymer_PET1',\n",
    "       'MajorityPolymer_PP1', 'MajorityPolymer_PP2', 'MajorityPolymer_PP3',\n",
    "       'MajorityPolymer_PS2', 'MinorityPolymer_LLDPE1', 'MinorityPolymer_PA1',\n",
    "       'MinorityPolymer_PP2', 'MinorityPolymer_PP3', 'MinorityPolymer_PS2'\n",
    "       \n",
    "       meaning the ratio of impurity; and the Mayority and minority polymer are not that relevant!\n",
    "       indeed as they are 1hotencoding they ressemble the most and thus do not help in predictions. \n",
    "       https://kgptalkie.com/feature-selection-with-filtering-method-constant-quasi-constant-and-duplicate-feature-removal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a66f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262, 25), (66, 25), (262, 37))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filter = constant_filter.transform(X_train)\n",
    "X_test_filter = constant_filter.transform(X_test)\n",
    "X_train_filter.shape, X_test_filter.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do out of link; Build ML model and compare the performance of the selected feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2b41b",
   "metadata": {},
   "source": [
    "**Pearsons Correlation\n",
    "from filetring apply corr for every col with target and find most avalauble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a90dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b190f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33789\\AppData\\Local\\Temp\\ipykernel_68592\\1613850035.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.35316944e-02 3.36614272e-02 5.82456317e-03 7.00420611e-03\n",
      " 5.95973542e-04 9.86614317e-03 1.83178999e-03 1.58479864e-03\n",
      " 4.51506908e-04 5.26540899e-03 1.82859030e-03 2.54095670e-03\n",
      " 6.89226751e-02 7.17763983e-01 2.25047032e-02 5.66388829e-02\n",
      " 1.32297126e-02 4.24046768e-03 2.13333928e-04 8.63008744e-05\n",
      " 7.02960341e-04 8.56466041e-04 2.13670731e-04 1.40615694e-04\n",
      " 6.69307454e-06 2.54566334e-02 3.26398479e-04 7.00971739e-04\n",
      " 1.06258837e-03 1.08628466e-03 1.11725285e-04 2.77106769e-04\n",
      " 2.27356334e-04 1.66991149e-04 3.59778145e-06 1.01499238e-03\n",
      " 5.78294000e-05]\n",
      "   MajorityPolymer_LLDPE1  MinorityPolymer_LDPE1  MajorityPolymer_PP2  \\\n",
      "0               -0.000189              -0.000805            -0.000014   \n",
      "1               -0.000201              -0.000304            -0.000012   \n",
      "2               -0.000250               0.000124            -0.000014   \n",
      "3               -0.000179               0.001271            -0.000022   \n",
      "4               -0.000159              -0.000690            -0.000004   \n",
      "5               -0.000114               0.000160            -0.000014   \n",
      "6               -0.000213              -0.000459            -0.000014   \n",
      "7               -0.000191              -0.000484            -0.000015   \n",
      "8               -0.000123              -0.000236            -0.000015   \n",
      "9               -0.000185               0.001241            -0.000010   \n",
      "\n",
      "   MajorityPolymer_PP3  MajorityPolymer_PS2  MinorityPolymer_PP3  \\\n",
      "0        -2.273284e-07                  0.0         3.579900e-07   \n",
      "1        -2.273284e-07                  0.0         3.579900e-07   \n",
      "2        -2.273284e-07                  0.0         3.579900e-07   \n",
      "3        -2.273284e-07                  0.0         3.579900e-07   \n",
      "4        -2.273284e-07                  0.0         3.579900e-07   \n",
      "5        -2.273284e-07                  0.0         3.579900e-07   \n",
      "6        -2.273284e-07                  0.0         3.579900e-07   \n",
      "7        -2.273284e-07                  0.0         3.579900e-07   \n",
      "8        -2.273284e-07                  0.0         3.579900e-07   \n",
      "9        -2.273284e-07                  0.0         3.579900e-07   \n",
      "\n",
      "   MinorityPolymer_PS2  MinorityPolymer_PET1  MinorityPolymer_PA1  \\\n",
      "0             0.000002              0.000079             0.000301   \n",
      "1             0.000002              0.000085             0.000011   \n",
      "2             0.000002              0.000081             0.000039   \n",
      "3             0.000002              0.000089            -0.000049   \n",
      "4             0.000002              0.000085             0.000039   \n",
      "5             0.000002             -0.000106             0.000039   \n",
      "6             0.000002             -0.000124             0.000039   \n",
      "7             0.000002             -0.000138            -0.000291   \n",
      "8             0.000002              0.000082             0.000039   \n",
      "9             0.000002              0.000039             0.000066   \n",
      "\n",
      "   MajorityPolymer_PP1  ...  Matrix_viscosity  Matrix_family  \\\n",
      "0             0.000062  ...          0.002844       0.007084   \n",
      "1             0.000030  ...          0.003480       0.004488   \n",
      "2            -0.000016  ...          0.002955       0.000881   \n",
      "3             0.000062  ...          0.002966       0.006613   \n",
      "4            -0.000006  ...          0.002446      -0.001076   \n",
      "5             0.000079  ...          0.002721       0.003262   \n",
      "6             0.000058  ...          0.002189       0.004313   \n",
      "7             0.000060  ...          0.002932       0.002995   \n",
      "8             0.000071  ...          0.003377       0.001582   \n",
      "9             0.000070  ...          0.002991       0.001798   \n",
      "\n",
      "   MajorityPolymer_PS1  Contaminant_SCB  Matrix_crystallinity  matrixXc  \\\n",
      "0             0.007814         0.000845              0.025857  0.022237   \n",
      "1             0.014769         0.000905              0.015339  0.019296   \n",
      "2             0.007173         0.012427              0.017692  0.020898   \n",
      "3             0.007295         0.015499              0.027540  0.010931   \n",
      "4             0.004353         0.013515              0.011434  0.016079   \n",
      "5             0.002212         0.013095              0.016857  0.020235   \n",
      "6             0.008238         0.010212              0.019806  0.027739   \n",
      "7             0.005199         0.013326              0.012125  0.022382   \n",
      "8             0.014595         0.012479              0.017465  0.022126   \n",
      "9             0.005424         0.015414              0.009769  0.015446   \n",
      "\n",
      "   impurityXc  impurityE  WeightImpurity   matrixE  \n",
      "0    0.014815   0.032086        0.233510  1.818481  \n",
      "1    0.023983   0.029006        0.106998  1.205277  \n",
      "2    0.037452   0.065844        0.209366  1.811669  \n",
      "3    0.020486   0.072441        0.287872  1.336300  \n",
      "4    0.015368   0.056267        0.191713  1.383111  \n",
      "5    0.014266   0.082066        0.288772  1.995861  \n",
      "6    0.041016   0.064456        0.313512  1.247674  \n",
      "7    0.031111   0.021139        0.181655  1.133953  \n",
      "8    0.042138   0.050327        0.315251  1.321634  \n",
      "9    0.010292   0.053339        0.281869  1.521112  \n",
      "\n",
      "[10 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#  import matplotlib as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('data/data_reduced.csv')\n",
    "\n",
    "xE = data.drop(['blendE','blendSTRENGTH','blendStrainbreak', 'blendImpact', 'impurityImpact', 'impuritySTRENGTH', 'impurityStrainbreak', 'matrixImpact', 'matrixSTRENGTH', 'matrixStrainbreak'], axis=1)\n",
    "yE = data[['blendE']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xE, yE, test_size=0.1, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.feature_importances_)\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=xE.columns[sorted_importances_idx],\n",
    ")\n",
    "print(importances)\n",
    "# ax = importances.plot.box(vert=False, whis=10)\n",
    "# ax.set_title(\"Permutation Importances (test set)\")\n",
    "# ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "# ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "# ax.figure.tight_layout()\n",
    "# ax.figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e873888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}